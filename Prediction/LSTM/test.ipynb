{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from copy import deepcopy as dc\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_path = '/workspaces/Futures-First/Prediction/LSTM/data/Corn/ZC Jul-Sep'\n",
    "temp_path = '/workspaces/Futures-First/Prediction/LSTM/data/Copper/HG Dec-Mar'\n",
    "# files = ['./data/2004.csv', './data/2005.csv', './data/2006.csv','./data/2007.csv', './data/2008.csv', './data/2009.csv','./data/2010.csv', './data/2011.csv', './data/2012.csv','./data/2013.csv', './data/2014.csv', './data/2015.csv','./data/2016.csv', './data/2017.csv', './data/2018.csv','./data/2019.csv', './data/2020.csv', './data/2021.csv','./data/2022.csv', './data/2023.csv', './data/2024.csv']  \n",
    "# files = [temp_path +'/2016.csv',temp_path +'/2017.csv', temp_path +'/2018.csv',temp_path +'/2019.csv', temp_path +'/2020.csv',temp_path +'/2021.csv',temp_path +'/2022.csv',temp_path +'/2023.csv',temp_path +'/2024.csv',temp_path +'/2025.csv']  \n",
    "files = [temp_path +'/2015.csv',temp_path +'/2016.csv',temp_path +'/2017.csv', temp_path +'/2018.csv',temp_path +'/2019.csv', temp_path +'/2020.csv',temp_path +'/2021.csv',temp_path +'/2022.csv',temp_path +'/2023.csv',temp_path +'/2024.csv']  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_stacked_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_stacked_layers = num_stacked_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_stacked_layers,\n",
    "                            batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = ['Open','High','Low','Close']\n",
    "tag_index = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function updates\n",
    "def train_one_epoch(train_loader, model, optimizer, loss_function, epoch):\n",
    "    model.train(True)\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_index, batch in enumerate(train_loader):\n",
    "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        output = model(x_batch)\n",
    "        loss = loss_function(output, y_batch)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_index % 100 == 99:  # print every 100 batches\n",
    "            avg_loss_across_batches = running_loss / 100\n",
    "            print(f'Batch {batch_index + 1}, Loss: {avg_loss_across_batches:.3f}')\n",
    "            running_loss = 0.0\n",
    "    print()\n",
    "\n",
    "def validate_one_epoch(test_loader, model, loss_function):\n",
    "    model.train(False)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_index, batch in enumerate(test_loader):\n",
    "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(x_batch)\n",
    "            loss = loss_function(output, y_batch)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    avg_loss_across_batches = running_loss / len(test_loader)\n",
    "\n",
    "    print(f'Val Loss: {avg_loss_across_batches:.3f}')\n",
    "    print('***************************************************')\n",
    "    print()\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "        def __init__(self, X, y):\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.X)\n",
    "\n",
    "        def __getitem__(self, i):\n",
    "            return self.X[i], self.y[i]\n",
    "# Main loop\n",
    "for file in files[:-1]:  # Exclude the current year's data for training\n",
    "    # Load and preprocess data\n",
    "    data = pd.read_csv(file)\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data = data.rename(columns={tag_list[tag_index] :'Price'})\n",
    "    data = data[['Date', 'Price']]\n",
    "    # plt.plot(data['Date'], data['Price'])\n",
    "    # plt.show()  # Show the plot for each file\n",
    "\n",
    "    # Prepare the data for training\n",
    "    def prepare_dataframe_for_lstm(df, n_steps):\n",
    "        df = dc(df)\n",
    "\n",
    "        df.set_index('Date', inplace=True)\n",
    "\n",
    "        for i in range(1, n_steps+1):\n",
    "            df[f'Price(t-{i})'] = df['Price'].shift(i)\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    lookback = 10\n",
    "    shifted_df = prepare_dataframe_for_lstm(data, lookback)\n",
    "\n",
    "    shifted_df_as_np = shifted_df.to_numpy()\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    shifted_df_as_np = scaler.fit_transform(shifted_df_as_np)\n",
    "\n",
    "    X = shifted_df_as_np[:, 1:]\n",
    "    y = shifted_df_as_np[:, 0]\n",
    "    X = dc(np.flip(X, axis=1))\n",
    "\n",
    "    X = X.reshape((-1, lookback, 1))\n",
    "    y = y.reshape((-1, 1))\n",
    "\n",
    "    X = torch.tensor(X).float()\n",
    "    y = torch.tensor(y).float()\n",
    "\n",
    "    train_dataset = TimeSeriesDataset(X, y)\n",
    "    \n",
    "    batch_size = 16\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for _, batch in enumerate(train_loader):\n",
    "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "        print(x_batch.shape, y_batch.shape)\n",
    "        break\n",
    "\n",
    "    model = LSTM(1, 4, 1)\n",
    "    model.to(device)\n",
    "    print(model)\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 100\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_one_epoch(train_loader, model, optimizer, loss_function, epoch)\n",
    "        validate_one_epoch(train_loader, model, loss_function)\n",
    "\n",
    "    torch.save(model.state_dict(), f'lstm_model_{file.split(\"/\")[-1].split(\".\")[0]}.pt')\n",
    "    with torch.no_grad():\n",
    "        predicted = model(X.to(device)).to('cpu').numpy()\n",
    "\n",
    "    plt.plot(y, label='Actual Close')\n",
    "    plt.plot(predicted, label='Predicted Close')\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Close')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from copy import deepcopy as dc\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Function to prepare data for LSTM\n",
    "def prepare_dataframe_for_lstm(df, n_steps):\n",
    "    df = dc(df)\n",
    "    df.set_index('Date', inplace=True)\n",
    "    for i in range(1, n_steps+1):\n",
    "        df[f'Price(t-{i})'] = df['Price'].shift(i)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "# Load and prepare the data\n",
    "data = pd.read_csv(files[-1])\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data.rename(columns={tag_list[tag_index]:'Price'})\n",
    "data = data[['Date', 'Price']]\n",
    "\n",
    "lookback = 10\n",
    "shifted_df = prepare_dataframe_for_lstm(data, lookback)\n",
    "\n",
    "shifted_df_as_np = shifted_df.to_numpy()\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "shifted_df_as_np = scaler.fit_transform(shifted_df_as_np)\n",
    "\n",
    "X = shifted_df_as_np[:, 1:]\n",
    "y = shifted_df_as_np[:, 0]\n",
    "X = dc(np.flip(X, axis=1))\n",
    "\n",
    "X = X.reshape((-1, lookback, 1))\n",
    "y = y.reshape((-1, 1))\n",
    "\n",
    "X_test = torch.tensor(X).float()\n",
    "y_test = torch.tensor(y).float()\n",
    "\n",
    "# Load the trained model\n",
    "model_file = '/workspaces/Futures-First/Prediction/LSTM/lstm_model_2023.pt'\n",
    "model = LSTM(input_size=1, hidden_size=4, num_stacked_layers=1).to(device)\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "model.eval()\n",
    "\n",
    "# Predict the last part of the dataset\n",
    "test_predictions = model(X_test.to(device)).detach().cpu().numpy().flatten()\n",
    "\n",
    "# Inverse transform the predictions\n",
    "dummies = np.zeros((X_test.shape[0], lookback+1))\n",
    "dummies[:, 0] = test_predictions\n",
    "dummies = scaler.inverse_transform(dummies)\n",
    "test_predictions = dc(dummies[:, 0])\n",
    "\n",
    "dummies = np.zeros((X_test.shape[0], lookback+1))\n",
    "dummies[:, 0] = y_test.flatten()\n",
    "dummies = scaler.inverse_transform(dummies)\n",
    "new_y_test = dc(dummies[:, 0])\n",
    "\n",
    "# Prepare for predicting future prices\n",
    "last_window = X_test[-1].cpu().numpy()\n",
    "\n",
    "future_predictions = []\n",
    "\n",
    "# Predict the next 5 days\n",
    "for _ in range(10):\n",
    "    # Predict the next price\n",
    "    pred = model(torch.tensor(last_window).unsqueeze(0).float().to(device)).detach().cpu().numpy().flatten()[0]\n",
    "    \n",
    "    # Scale back to original price\n",
    "    dummies = np.zeros((1, lookback + 1))\n",
    "    dummies[:, 0] = pred\n",
    "    dummies = scaler.inverse_transform(dummies)\n",
    "    \n",
    "    pred_original = dummies[:, 0][0]\n",
    "    future_predictions.append(pred_original)\n",
    "    \n",
    "    # Update the window for the next prediction\n",
    "    last_window = np.roll(last_window, -1)\n",
    "    last_window[-1, 0] = pred\n",
    "\n",
    "# Combine all predictions\n",
    "all_predictions = np.concatenate((test_predictions, np.array(future_predictions)))\n",
    "\n",
    "# Create plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces for actual and predicted values\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.arange(len(new_y_test)),\n",
    "    y=new_y_test,\n",
    "    mode='lines',\n",
    "    name='Actual Close'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.arange(len(test_predictions)),\n",
    "    y=test_predictions,\n",
    "    mode='lines',\n",
    "    name='Predicted Close (Past)'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.arange(len(test_predictions), len(all_predictions)),\n",
    "    y=future_predictions,\n",
    "    mode='lines',\n",
    "    name='Predicted Close (Future)',\n",
    "    # line=dict(dash='dash')\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"ZW Futures Price Prediction\",\n",
    "    xaxis_title=\"Day\",\n",
    "    yaxis_title=\"Price\",\n",
    "    legend_title=\"Legend\"\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_num = [f\"{number:.4f}\" for number in future_predictions]\n",
    "future_num,tag_list[tag_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HG-\n",
    "\n",
    "OPEN =    -0.0390,-0.0404,-0.0393,-0.0384\n",
    "\n",
    "HIGH =    -0.0385,-0.0365,-0.0355,-0.0346\n",
    "\n",
    "LOW =     -0.0420,-0.0419,-0.0409,-0.0401\n",
    "\n",
    "CLOSE=    -0.0405,-0.0388,-0.0379,-0.0370\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZW Dec Mar- \n",
    "\n",
    "OPEN -  -21.00\n",
    "        -19.0099  -18.7063  -18.4336\n",
    "\n",
    "HIGH - -20.75\n",
    "       -18.3430   -18.1017  -17.9478\n",
    "\n",
    "LOW-    -21.25\n",
    "        -19.6267'  '-19.2615'  '-18.9909'\n",
    "\n",
    "CLOSE-  -21.00\n",
    "        -19.3360  -18.9063  -18.6242"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZC\n",
    "OPEN - 1.25\n",
    "       1.1289  1.3446  1.5681\n",
    "\n",
    "HIGH - 3.25\n",
    "       0.9690  1.0174  1.0735\n",
    "\n",
    "LOW-   1.25\n",
    "       0.5462  0.7300  0.9205\n",
    "\n",
    "CLOSE- 3.00\n",
    "       2.0662     2.7128    3.4458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "# OHLC data for two days\n",
    "ohlc = {\n",
    "    'Open': [-0.0390,-0.0404,-0.0393,-0.0384],\n",
    "    'High': [-0.0385,-0.0365,-0.0355,-0.0346],\n",
    "    'Low': [-0.0420,-0.0419,-0.0409,-0.0401],\n",
    "    'Close': [-0.0405,-0.0388,-0.0379,-0.0370]\n",
    "}\n",
    "\n",
    "# Dates for the candlesticks\n",
    "dates = ['2024-08-25','2024-08-26', '2024-08-27','2024-08-28']\n",
    "\n",
    "# Create a candlestick chart\n",
    "candle = go.Candlestick(\n",
    "    x=['T_real','T-1','T','T+1'],  \n",
    "    open=ohlc['Open'],\n",
    "    high=ohlc['High'],\n",
    "    low=ohlc['Low'],\n",
    "    close=ohlc['Close']\n",
    ")\n",
    "\n",
    "# Create a figure and add the candlestick\n",
    "fig = go.Figure(data=[candle])\n",
    "\n",
    "# Update layout to show titles\n",
    "fig.update_layout(title='Candlesticks', xaxis_title='Date', yaxis_title='Price')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
