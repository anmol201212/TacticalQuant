{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from copy import deepcopy as dc\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import shutil\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = \"/workspaces/Futures-First/Prediction/LSTM/data\"\n",
    "files = []\n",
    "def list_folders(folder_path):\n",
    "    # List only subdirectories (folders) in the given folder path\n",
    "    return [d for d in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, d))]\n",
    "\n",
    "def select_folder(folder_list, folder_path):\n",
    "    # Show subfolders to select from\n",
    "    print(\"\\nSubfolders:\")\n",
    "    for i, folder in enumerate(folder_list, 1):\n",
    "        print(f\"{i}. {folder}\")\n",
    "    \n",
    "    # Get the user's choice\n",
    "    choice = int(input(\"\\nSelect the number of the folder: \")) - 1\n",
    "    return os.path.join(folder_path, folder_list[choice])\n",
    "\n",
    "# List folders in the main folder and select one\n",
    "subfolders = list_folders(main_folder)\n",
    "first_selected_folder = select_folder(subfolders, main_folder)\n",
    "\n",
    "# List folders in the first selected folder and select one\n",
    "subfolders_in_first = list_folders(first_selected_folder)\n",
    "second_selected_folder = select_folder(subfolders_in_first, first_selected_folder)\n",
    "\n",
    "# Print all files in the second selected folder\n",
    "# print(f\"\\nFiles in '{second_selected_folder}':\")\n",
    "for file_name in os.listdir(second_selected_folder):\n",
    "    if os.path.isfile(os.path.join(second_selected_folder, file_name)):\n",
    "        # print(file_name)\n",
    "        files.append(second_selected_folder +'/' +file_name)\n",
    "files.sort()\n",
    "files        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_contents(folder_path):\n",
    "    # List all items (files and folders) in the directory\n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "\n",
    "        # If it's a file, remove it\n",
    "        if os.path.isfile(item_path):\n",
    "            os.remove(item_path)\n",
    "            print(f\"Deleted file: {item_path}\")\n",
    "        \n",
    "        # If it's a folder, remove it and its contents\n",
    "        elif os.path.isdir(item_path):\n",
    "            shutil.rmtree(item_path)\n",
    "            # print(f\"Deleted folder: {item_path}\")\n",
    "\n",
    "# Provide the path to the folder you want to clean\n",
    "folder_to_clean = '/workspaces/Futures-First/Prediction/LSTM/test'\n",
    "delete_contents(folder_to_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_stacked_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_stacked_layers = num_stacked_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_stacked_layers,\n",
    "                            batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "def train_one_epoch(train_loader, model, optimizer, loss_function, epoch):\n",
    "    model.train(True)\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_index, batch in enumerate(train_loader):\n",
    "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        output = model(x_batch)\n",
    "        loss = loss_function(output, y_batch)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_index % 100 == 99:  # print every 100 batches\n",
    "            avg_loss_across_batches = running_loss / 100\n",
    "            print(f'Batch {batch_index + 1}, Loss: {avg_loss_across_batches:.3f}')\n",
    "            running_loss = 0.0\n",
    "    print()\n",
    "\n",
    "def validate_one_epoch(test_loader, model, loss_function):\n",
    "    model.train(False)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_index, batch in enumerate(test_loader):\n",
    "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(x_batch)\n",
    "            loss = loss_function(output, y_batch)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    avg_loss_across_batches = running_loss / len(test_loader)\n",
    "\n",
    "    print(f'Val Loss: {avg_loss_across_batches:.3f}')\n",
    "    print('***************************************************')\n",
    "    print()\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "        def __init__(self, X, y):\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.X)\n",
    "\n",
    "        def __getitem__(self, i):\n",
    "            return self.X[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = ['Open','High','Low','Close']\n",
    "for tag_name in tag_list:\n",
    "    for file in files[:-1]:  # Exclude the current year's data for training\n",
    "        # Load and preprocess data\n",
    "        data = pd.read_csv(file)\n",
    "        data['Date'] = pd.to_datetime(data['Date'])\n",
    "        data = data.rename(columns={tag_name :'Price'})\n",
    "        data = data[['Date', 'Price']]\n",
    "        # plt.plot(data['Date'], data['Price'])\n",
    "        # plt.show()  # Show the plot for each file\n",
    "\n",
    "        # Prepare the data for training\n",
    "        def prepare_dataframe_for_lstm(df, n_steps):\n",
    "            df = dc(df)\n",
    "\n",
    "            df.set_index('Date', inplace=True)\n",
    "\n",
    "            for i in range(1, n_steps+1):\n",
    "                df[f'Price(t-{i})'] = df['Price'].shift(i)\n",
    "\n",
    "            df.dropna(inplace=True)\n",
    "\n",
    "            return df\n",
    "\n",
    "        lookback = 10\n",
    "        shifted_df = prepare_dataframe_for_lstm(data, lookback)\n",
    "\n",
    "        shifted_df_as_np = shifted_df.to_numpy()\n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        shifted_df_as_np = scaler.fit_transform(shifted_df_as_np)\n",
    "\n",
    "        X = shifted_df_as_np[:, 1:]\n",
    "        y = shifted_df_as_np[:, 0]\n",
    "        X = dc(np.flip(X, axis=1))\n",
    "\n",
    "        X = X.reshape((-1, lookback, 1))\n",
    "        y = y.reshape((-1, 1))\n",
    "\n",
    "        X = torch.tensor(X).float()\n",
    "        y = torch.tensor(y).float()\n",
    "\n",
    "        train_dataset = TimeSeriesDataset(X, y)\n",
    "        \n",
    "        batch_size = 16\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        for _, batch in enumerate(train_loader):\n",
    "            x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "            print(x_batch.shape, y_batch.shape)\n",
    "            break\n",
    "\n",
    "        model = LSTM(1, 4, 1)\n",
    "        model.to(device)\n",
    "        print(model)\n",
    "\n",
    "        learning_rate = 0.001\n",
    "        num_epochs = 100\n",
    "        loss_function = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            train_one_epoch(train_loader, model, optimizer, loss_function, epoch)\n",
    "            validate_one_epoch(train_loader, model, loss_function)\n",
    "        save_path = f'/workspaces/Futures-First/Prediction/LSTM/test/{tag_name}/'\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(save_path, f'lstm_model_{file.split(\"/\")[-1].split(\".\")[0]}.pt'))\n",
    "        with torch.no_grad():\n",
    "            predicted = model(X.to(device)).to('cpu').numpy()\n",
    "\n",
    "        plt.plot(y, label='Actual Close')\n",
    "        plt.plot(predicted, label='Predicted Close')\n",
    "        plt.xlabel('Day')\n",
    "        plt.ylabel('Close')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(files[-1])\n",
    "last_row = df[['Open', 'High', 'Low', 'Close']].iloc[-1]\n",
    "\n",
    "ohlc = {\n",
    "    'Open': [last_row['Open']],\n",
    "    'High': [last_row['High']],\n",
    "    'Low': [last_row['Low']],\n",
    "    'Close': [last_row['Close']]\n",
    "}\n",
    "\n",
    "# ohlc = {\n",
    "#     'Open': np.float64(last_row['Open']),\n",
    "#     'High': np.float64(last_row['High']),\n",
    "#     'Low': np.float64(last_row['Low']),\n",
    "#     'Close': np.float64(last_row['Close'])\n",
    "# }\n",
    "print(ohlc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag_name in tag_list:\n",
    "    # Function to prepare data for LSTM\n",
    "    def prepare_dataframe_for_lstm(df, n_steps):\n",
    "        df = dc(df)\n",
    "        df.set_index('Date', inplace=True)\n",
    "        for i in range(1, n_steps+1):\n",
    "            df[f'Price(t-{i})'] = df['Price'].shift(i)\n",
    "        df.dropna(inplace=True)\n",
    "        return df\n",
    "\n",
    "    # Load and prepare the data\n",
    "    data = pd.read_csv(files[-1])\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data = data.rename(columns={tag_name:'Price'})\n",
    "    data = data[['Date', 'Price']]\n",
    "\n",
    "    lookback = 10\n",
    "    shifted_df = prepare_dataframe_for_lstm(data, lookback)\n",
    "\n",
    "    shifted_df_as_np = shifted_df.to_numpy()\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    shifted_df_as_np = scaler.fit_transform(shifted_df_as_np)\n",
    "\n",
    "    X = shifted_df_as_np[:, 1:]\n",
    "    y = shifted_df_as_np[:, 0]\n",
    "    X = dc(np.flip(X, axis=1))\n",
    "\n",
    "    X = X.reshape((-1, lookback, 1))\n",
    "    y = y.reshape((-1, 1))\n",
    "\n",
    "    X_test = torch.tensor(X).float()\n",
    "    y_test = torch.tensor(y).float()\n",
    "\n",
    "    # Load the trained model\n",
    "    model_file = '/workspaces/Futures-First/Prediction/LSTM/test/'+tag_name+'/lstm_model_'+files[-1][-8:-4]+'.pt'\n",
    "    model = LSTM(input_size=1, hidden_size=4, num_stacked_layers=1).to(device)\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model.eval()\n",
    "\n",
    "    # Predict the last part of the dataset\n",
    "    test_predictions = model(X_test.to(device)).detach().cpu().numpy().flatten()\n",
    "\n",
    "    # Inverse transform the predictions\n",
    "    dummies = np.zeros((X_test.shape[0], lookback+1))\n",
    "    dummies[:, 0] = test_predictions\n",
    "    dummies = scaler.inverse_transform(dummies)\n",
    "    test_predictions = dc(dummies[:, 0])\n",
    "\n",
    "    dummies = np.zeros((X_test.shape[0], lookback+1))\n",
    "    dummies[:, 0] = y_test.flatten()\n",
    "    dummies = scaler.inverse_transform(dummies)\n",
    "    new_y_test = dc(dummies[:, 0])\n",
    "\n",
    "    # Prepare for predicting future prices\n",
    "    last_window = X_test[-1].cpu().numpy()\n",
    "\n",
    "    future_predictions = []\n",
    "\n",
    "    # Predict the next 5 days\n",
    "    for _ in range(10):\n",
    "        # Predict the next price\n",
    "        pred = model(torch.tensor(last_window).unsqueeze(0).float().to(device)).detach().cpu().numpy().flatten()[0]\n",
    "        \n",
    "        # Scale back to original price\n",
    "        dummies = np.zeros((1, lookback + 1))\n",
    "        dummies[:, 0] = pred\n",
    "        dummies = scaler.inverse_transform(dummies)\n",
    "        \n",
    "        pred_original = dummies[:, 0][0]\n",
    "        future_predictions.append(pred_original)\n",
    "        \n",
    "        # Update the window for the next prediction\n",
    "        last_window = np.roll(last_window, -1)\n",
    "        last_window[-1, 0] = pred\n",
    "\n",
    "    # Combine all predictions\n",
    "    all_predictions = np.concatenate((test_predictions, np.array(future_predictions)))\n",
    "\n",
    "    # Create plotly figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add traces for actual and predicted values\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.arange(len(new_y_test)),\n",
    "        y=new_y_test,\n",
    "        mode='lines',\n",
    "        name='Actual Close'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.arange(len(test_predictions)),\n",
    "        y=test_predictions,\n",
    "        mode='lines',\n",
    "        name='Predicted Close (Past)'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.arange(len(test_predictions), len(all_predictions)),\n",
    "        y=future_predictions,\n",
    "        mode='lines',\n",
    "        name='Predicted Close (Future)',\n",
    "        # line=dict(dash='dash')\n",
    "    ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=\"Futures Price Prediction\",\n",
    "        xaxis_title=\"Day\",\n",
    "        yaxis_title=\"Price\",\n",
    "        legend_title=\"Legend\"\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "    # future_num = [f\"{number:.4f}\" for number in future_predictions]\n",
    "    ohlc[tag_name].extend(future_predictions[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candle = go.Candlestick(\n",
    "    x=['T_real','T-1','T','T+1'],  \n",
    "    open=ohlc['Open'],\n",
    "    high=ohlc['High'],\n",
    "    low=ohlc['Low'],\n",
    "    close=ohlc['Close']\n",
    ")\n",
    "\n",
    "# Create a figure and add the candlestick\n",
    "fig = go.Figure(data=[candle])\n",
    "\n",
    "# Update layout to show titles\n",
    "fig.update_layout(title='Candlesticks', xaxis_title='Date', yaxis_title='Price')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
